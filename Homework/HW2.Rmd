---
title: "BIOST 544 Homework 2"
author: "Hantong Hu"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
library(tidyverse)
knitr::opts_chunk$set(echo = F)
```

# Responses

1. The "one.simple.perm" function takes in data from that described in Q1 and runs one simple permutation/re-randomization test. Then the "simple.perm" function reruns this process for a number of times and provides a p-value that demonstrates the probability that within the data, how likely standard-of-care (tx=0) is at least as effective as new-treatment (tx=1). To test, I created a data set that has 100 controls with probability of outcome from 0.1 to 0.9 (0.1, 0.2, ..., 0.9) and 100 treatments with probability of outcome at 0.7. Apparently, the p values get larger when controls have higher probability of outcome. 

```{r q1, warning=FALSE, message=FALSE, echo =T}
## Q1
one.simple.perm <- function(dat) {
  tx.new <- sample(dat$tx)
  dat.new <- data.frame(tx = tx.new, outcome = dat$outcome)
  
  dat_diff <- dat.new %>% filter(tx == 0) %>% .$outcome %>% mean() -
    dat.new %>% filter(tx == 1) %>% .$outcome %>% mean()
  
  return(dat_diff)
}

simple.perm <- function(dat, ntrial=1e3){
  dat_diff <- replicate(ntrial, one.simple.perm(dat))

  pooled_diff <- dat %>% filter(tx == 1) %>% .$outcome %>% mean() -
    dat %>% filter(tx == 0) %>% .$outcome %>% mean()
  
  lower_percentile <- mean(pooled_diff <= dat_diff)
  
  return(list(diff=dat_diff,prob=lower_percentile))
}

set.seed(1)
pval <- rep(0, 9)
for (i in seq(0.1, 0.9, 0.1)) {
  pval[i * 10] <-
    simple.perm(dat = data.frame(
      tx = c(rep(0, times = 100),
             rep(1, times = 100)),
      outcome = c(rbinom(100, 1, i), rbinom(100, 1, 0.7))
    ))$prob
  
}


knitr::kable(data.frame(ctl.outcome.prop=seq(0.1,0.9,0.1),p_value=pval),
             caption = "P value for standard-of-care at least as effective as 
             new-treatment when tx.outcome.prop=0.7.")
```

2. (a) In the following code, "pnew.tx" is a function to determine tx from previous data set. The "one.rerand.test" function takes in data from that described in Q2 and runs one adaptive permutation/re-randomization test using the pnew.tx function. Then the "rerand.test" function reruns this process for a number of times and provides a p-value that demonstrates the probability that within the data, how likely standard-of-care (tx=0) is at least as effective as new-treatment (tx=1).

```{r q2a, warning=FALSE, message=FALSE, echo =T}
## Q2a
# A function to determine tx from pnew
pnew.tx <- function(dat){
  suc.new <- dat %>% filter(tx==1 & outcome==1) %>% nrow()
  fai.old <- dat %>% filter(tx==0 & outcome==0) %>% nrow()
  
  pnew <- (1+3*(suc.new+fai.old))/(2+3*nrow(dat))

  tx.assigned <- rbinom(1,1,pnew)
  return(tx.assigned)
}

one.rerand.test <- function(dat) {
  ordered.dat <- dat %>% arrange(order)
  
  rerand.tx <-
    data.frame(tx = rep(NA, nrow(ordered.dat)), outcome = ordered.dat$outcome)
  rerand.tx[1,1] <- pnew.tx(rerand.tx[0,])
  
  for (i in c(1:nrow(ordered.dat) - 1)) {
    tx <- pnew.tx(rerand.tx[c(1:i),])
    rerand.tx[i + 1, 1] <- tx
  }
  
  dat_diff <- rerand.tx %>% filter(tx == 1) %>% .$outcome %>% mean() -
    rerand.tx %>% filter(tx == 0) %>% .$outcome %>% mean()
  
  return(dat_diff)
}

rerand.test <- function(dat, ntrial=1e3){
  diffs <- replicate(ntrial, one.rerand.test(dat))
    
  pooled_diff <- dat %>% filter(tx == 1) %>% .$outcome %>% mean() -
    dat %>% filter(tx == 0) %>% .$outcome %>% mean()
  
  lower_percentile <- mean(pooled_diff <= diffs)
  
  return(list(diff=diffs,prob=lower_percentile))
}
```

> (b) The probability is given as following

```{r q2b, warning=FALSE, message=FALSE, echo =F}
## Q2b
dat <- read.delim("HW2-adaptive-trial.txt", sep = ",")
set.seed(1)
q2_stat <- rerand.test(dat, 1e3)
(q2_stat$prob)
```

3. The probability generated by simple permutation is given as following. From these two numbers, we know these two methods don't differ by a lot. The density plot further proves this because they have similar distributions.

```{r q3, warning=FALSE, message=FALSE, echo = F}
## Q3
set.seed(1)
q1_stat <- simple.perm(dat,1e3)
(q1_stat$prob)

dens_plot <- rbind(data.frame(diff=q1_stat$diff, rand="simple"),
                   data.frame(diff=q2_stat$diff, rand="adaptive"))

ggplot(dens_plot, aes(x=diff, y=..density.., color=rand)) + 
  geom_density()
```

\pagebreak

# Code
```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```